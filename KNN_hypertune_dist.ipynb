{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Tbm2CFpZqA9o",
    "outputId": "c19b37ad-9bb0-4c45-a3e2-cccdc5b9af57"
   },
   "outputs": [],
   "source": [
    "# 1.0 - TensorFlow model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imutils import paths\n",
    "import h5py\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "#from cnn_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UfQfpkfq8Jv"
   },
   "outputs": [],
   "source": [
    "# Mount data from google drive    \n",
    "# Dataset to be imported below:\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lT5ZlRIl3zbT",
    "outputId": "12cbc05a-e453-4526-f33e-ac43f77c1e32"
   },
   "outputs": [],
   "source": [
    "#Load Datasets\n",
    "#X_data = h5py.File('/content/gdrive/Team Drives/CS 230 Project/Cereal pics/X_data.h5', 'r')\n",
    "#Y_data = h5py.File('/content/gdrive/Team Drives/CS 230 Project/Cereal pics/Y_data.h5', 'r')\n",
    "  \n",
    "X_data = h5py.File('X_data.h5', 'r')\n",
    "Y_data = h5py.File('Y_data.h5', 'r')\n",
    "  \n",
    "#Specify Split ratios\n",
    "Train_percent = 0.97\n",
    "Dev_percent = 0.0\n",
    "Test_percent = 0.03\n",
    "\n",
    "#Get shapes of data:\n",
    "m = len(X_data)\n",
    "h_X,w_X,c_X = np.shape(X_data['X1'])\n",
    "\n",
    "#Get indices of train/dev/test split\n",
    "temp_list = list(range(m))\n",
    "shuffle(temp_list)\n",
    "Train_list = temp_list[0:int(Train_percent*m)]\n",
    "Dev_list = temp_list[int(Train_percent*m):int(Train_percent*m)+int(Dev_percent*m)]\n",
    "Test_list = temp_list[int(Train_percent*m)+int(Dev_percent*m):\n",
    "                      int(Train_percent*m)+int(Dev_percent*m)+int(Test_percent*m)]\n",
    "\n",
    "# Create np arrays for train/dev/test set\n",
    "X_train_orig = np.empty((len(Train_list),h_X,w_X,c_X))\n",
    "Y_train_orig = np.empty(len(Train_list))\n",
    "X_dev_orig = np.empty((len(Dev_list),h_X,w_X,c_X))\n",
    "Y_dev_orig = np.empty(len(Dev_list))\n",
    "X_test_orig = np.empty((len(Test_list),h_X,w_X,c_X))\n",
    "Y_test_orig = np.empty(len(Test_list))\n",
    "\n",
    "#Copy data from dataset onto the np arrays\n",
    "for ind,item in enumerate(Train_list):\n",
    "    X_train_orig[ind]=X_data['X'+str(item)][:]\n",
    "    Y_train_orig[ind]=Y_data['y'+str(item)][:]\n",
    "for ind,item in enumerate(Dev_list):\n",
    "    X_dev_orig[ind]=X_data['X'+str(item)][:]\n",
    "    Y_dev_orig[ind]=Y_data['y'+str(item)][:]\n",
    "for ind,item in enumerate(Test_list):\n",
    "    X_test_orig[ind]=X_data['X'+str(item)][:]\n",
    "    Y_test_orig[ind]=Y_data['y'+str(item)][:]\n",
    "\n",
    "print(\"Done building dataset\")\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "z1yJWAynq8Yf",
    "outputId": "c6f1d623-8b9e-4b5c-ae90-51437f3e56cb"
   },
   "outputs": [],
   "source": [
    "# To get started, let's examine the shapes of your data.\n",
    "X_train = np.reshape(X_train_orig/255.,(X_train_orig.shape[0],256*256*3),order='C')\n",
    "X_dev = np.reshape(X_dev_orig/255.,(X_dev_orig.shape[0],256*256*3),order='C')\n",
    "X_test = np.reshape(X_test_orig/255.,(X_test_orig.shape[0],256*256*3),order='C')\n",
    "Y_train = Y_train_orig\n",
    "Y_dev = Y_dev_orig\n",
    "Y_test = Y_test_orig\n",
    "X_train_orig, X_dev_orig, X_test_orig = None, None, None\n",
    "Y_train_orig, Y_dev_orig, Y_test_orig = None, None, None\n",
    "del X_data\n",
    "del Y_data\n",
    "X_train = scale(X_train)\n",
    "X_test = scale(X_test)\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "pca.fit(X_test)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of dev examples = \" + str(X_dev.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(Y_dev.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dq7otX02_lGg"
   },
   "outputs": [],
   "source": [
    "# subsetting just the odd ones\n",
    "neighbors = [1,3,7,25]\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k,n_jobs=-1)\n",
    "    scores = cross_val_score(knn, X_train, Y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ju9pSUmCN7q"
   },
   "outputs": [],
   "source": [
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.xticks(np.arange(1, 20, step=2))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGMSE30pCbuI"
   },
   "outputs": [],
   "source": [
    "np.argmax(pred[0])\n",
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KNN - Ash.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
